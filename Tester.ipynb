{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing as mp\n",
    "import copy\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import torchmetrics\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "\n",
    "global ff_dim\n",
    "size = 20\n",
    "type = \"NR\"\n",
    "ff_dim = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(10)\n",
    "b = a + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1197.6054044463294"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f1(a, b):\n",
    "    diff = []\n",
    "    for i,j in zip(a,b):\n",
    "        gap = j.item() - i.item()\n",
    "        diff.append(gap/i.item())\n",
    "    \n",
    "    return np.mean(diff)*100\n",
    "\n",
    "f1(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1197.6054191589355"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f2(a,b):\n",
    "    gaps = b-a\n",
    "\n",
    "    return torch.mean(torch.div(gaps,a)).item()*100\n",
    "\n",
    "f2(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self,TSP_size,ff_dim):\n",
    "      \n",
    "        self.TSP_size = TSP_size\n",
    "        self.ff_dim = ff_dim\n",
    "        self.n_layers = math.ceil(math.log(TSP_size,2))\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.encoder = nn.TransformerEncoderLayer(d_model=self.TSP_size, nhead=self.TSP_size//10, batch_first=True, dim_feedforward=self.ff_dim)\n",
    "        self.transformer = nn.TransformerEncoder(self.encoder,num_layers=self.n_layers)      \n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "      \n",
    "        x = F.relu(x)\n",
    "        \n",
    "        out1 = self.transformer(x)\n",
    "        out2 = torch.transpose(out1, 1, 2)\n",
    "        x1 = F.softmax(out1,1)\n",
    "        x2 = F.softmax(out2,2)\n",
    "        x3 = torch.add(x1, x2)\n",
    "        x4 = F.hardtanh(x3, 0, 1)\n",
    "\n",
    "        return x4\n",
    "\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def is_symmetric(matrix):\n",
    "    # Check if the matrix is equal to its transpose\n",
    "    return torch.allclose(matrix, matrix.t())\n",
    "    \n",
    "\n",
    "# %%\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.tsp_size = (data.shape[1]-1)//3\n",
    "        self.data = data[:,:2*self.tsp_size]\n",
    "        self.lengths = data[:,-1]\n",
    "        self.labels = data[:,2*self.tsp_size:3*self.tsp_size]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_data = self.data[idx]\n",
    "        sample_label = self.labels[idx]\n",
    "        sample_lengths = self.lengths[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            sample_data,sample_label,sample_raw_dist = self.transform((sample_data,sample_label))\n",
    "            \n",
    "\n",
    "        return sample_data, sample_label, sample_raw_dist, sample_lengths\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, data):\n",
    "\n",
    "        sample_data = data[0]\n",
    "        sample_label = data[1]\n",
    "        \n",
    "        size = sample_data.shape[0]//2\n",
    "        X = np.column_stack((sample_data[:size], sample_data[size:]))\n",
    "        dist = euclidean_distances(X,X)\n",
    "        dist_ = dist/np.max(dist)\n",
    "        dist_ = 1-dist_\n",
    "        np.fill_diagonal(dist_, 0)\n",
    "        dist_ = torch.tensor(dist_, dtype=torch.float32)\n",
    "        dist = torch.tensor(dist, dtype=torch.float32)\n",
    "\n",
    "        mroutelist = sample_label.tolist()\n",
    "        mroutelist.append(0)\n",
    "        route_matrix = np.zeros((size,size))\n",
    "        \n",
    "        for i in range(size):\n",
    "            origin = int(mroutelist[i])\n",
    "            dest = int(mroutelist[i+1])\n",
    "            route_matrix[origin,dest] = 1\n",
    "            route_matrix[dest,origin] = 1\n",
    "     \n",
    "\n",
    "        route_matrix = torch.tensor(route_matrix, dtype=torch.float32)\n",
    "\n",
    "        return dist_, route_matrix, dist\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "data = np.loadtxt(\"BenchmarkInstances/{}_{}.csv\".format(type, size), delimiter=',')\n",
    "\n",
    "#train, val = train_test_split(data, random_state=42, test_size=0.05)\n",
    "\n",
    "# %%\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "#train_dataset = CustomDataset(train, transform=ToTensor())\n",
    "#train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_cores)\n",
    "\n",
    "val_dataset = CustomDataset(data, transform=ToTensor())\n",
    "val_data_loader = DataLoader(val_dataset, batch_size = len(data), shuffle=False, num_workers=num_cores)\n",
    "\n",
    "# %%\n",
    "model = Net(size,ff_dim=ff_dim)\n",
    "print(count_parameters(model))\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"best_model_{}.pth\".format(size), map_location=torch.device('cpu')))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode_batch(output_matrix, distance_matrix):\n",
    "    batch_size, num_points, _ = output_matrix.size()\n",
    "\n",
    "    # Initialize the tour tensor\n",
    "    best_tour = torch.zeros(batch_size, num_points, dtype=torch.long)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "       output_matrix[i].fill_diagonal_(0)\n",
    "\n",
    "\n",
    "    best_tour_length = torch.full((batch_size,), float('inf'))\n",
    "\n",
    "    for start_point in range(num_points):\n",
    "        # Start from the current point for each instance in the batch\n",
    "        current_points = torch.full((batch_size,), start_point, dtype=torch.long)\n",
    "        visited_points = torch.zeros(batch_size, num_points, dtype=torch.bool)\n",
    "        tour = torch.zeros(batch_size, num_points, dtype=torch.long)\n",
    "        tour[torch.arange(batch_size),0] = current_points\n",
    "\n",
    "        # Perform greedy decoding for the current starting point\n",
    "        for step in range(num_points-1):\n",
    "            visited_points[torch.arange(batch_size), current_points] = True\n",
    "            probabilities = output_matrix[torch.arange(batch_size), current_points, :]\n",
    "            probabilities[visited_points] = 0\n",
    "            # Choose the next point with the highest probability\n",
    "            next_points = torch.argmax(probabilities, dim=-1)\n",
    "            tour[:, step+1] = next_points\n",
    "            \n",
    "            current_points = next_points\n",
    "\n",
    "        # Calculate the tour length for each sample in the batch\n",
    "        tour_lengths = torch.sum(distance_matrix[torch.arange(batch_size).unsqueeze(1), tour, torch.roll(tour, shifts=-1, dims=1)], dim=-1)\n",
    "        # Update the best tour if the current one has a shorter length\n",
    "        update_mask = tour_lengths < best_tour_length\n",
    "        best_tour[update_mask] = tour[update_mask]\n",
    "        best_tour_length[update_mask] = tour_lengths[update_mask]\n",
    "\n",
    "    return best_tour, best_tour_length\n",
    "\n",
    "\n",
    "def greedy_total(output_matrix, normalized_dist, distance_matrix):\n",
    "\n",
    "    pred_tour, pred_tour_length = greedy_decode_batch(output_matrix, distance_matrix)\n",
    "\n",
    "    sum_tour, sum_tour_length = greedy_decode_batch(1-normalized_dist + output_matrix, distance_matrix)\n",
    "\n",
    "    mult_tour, mult_tour_length = greedy_decode_batch((1 - normalized_dist) * output_matrix, distance_matrix)\n",
    "\n",
    "\n",
    "    all_tour_lengths = torch.stack([pred_tour_length, sum_tour_length, mult_tour_length], dim=-1)\n",
    "    all_tours = torch.stack([pred_tour, sum_tour, mult_tour], dim=-1)\n",
    "\n",
    "    _, min_indices = torch.min(all_tour_lengths, dim=-1)\n",
    "    min_tour_lengths = torch.gather(all_tour_lengths, dim=-1, index=min_indices.unsqueeze(-1)).squeeze(-1)\n",
    "    min_tours = all_tours[torch.arange(all_tours.size(0)).unsqueeze(1), :, min_indices.unsqueeze(-1)]\n",
    "\n",
    "    return min_tours.squeeze(1), min_tour_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_tour_length(distance_matrix, tour):\n",
    "    \n",
    "    batch_size, num_points, _ = distance_matrix.size()\n",
    "    \n",
    "    # Create a tensor to hold the tour lengths for each batch\n",
    "\n",
    "    tour_lengths = torch.sum(distance_matrix[torch.arange(batch_size).unsqueeze(1), tour, torch.roll(tour, shifts=-1, dims=1)], dim=-1)\n",
    "\n",
    "\n",
    "    return tour_lengths\n",
    "\n",
    "def two_opt_swap(tour, i, j):\n",
    "    # Perform 2-opt swap between edges (i, i+1) and (j, j+1)\n",
    "    new_tour = tour.clone()\n",
    "    new_tour[:, i:j+1] =torch.flip(tour[:, i:j+1], dims=[1])\n",
    "    return new_tour\n",
    "\n",
    "def two_opt(distance_matrix, tour):\n",
    "    batch_size, num_points, _ = distance_matrix.size()\n",
    "\n",
    "    # Calculate the initial tour length\n",
    "    initial_tour_length = calculate_tour_length(distance_matrix, tour)\n",
    "\n",
    "    # Perform 2-opt swaps\n",
    "    for i in range(1, num_points - 2):\n",
    "        for j in range(i + 1, num_points):\n",
    "            # Calculate the new tour length after the 2-opt swap\n",
    "            new_tour = two_opt_swap(tour, i, j)\n",
    "            new_tour_length = calculate_tour_length(distance_matrix, new_tour)\n",
    "            # Identify tours with shorter lengths\n",
    "            improve_mask = new_tour_length < initial_tour_length\n",
    "            \n",
    "            # Update tours and lengths for improved cases\n",
    "            tour[improve_mask] = new_tour[improve_mask]\n",
    "            initial_tour_length[improve_mask] = new_tour_length[improve_mask]\n",
    "\n",
    "    return tour, initial_tour_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GreedyDecoder(val_data_loader, model):\n",
    "\n",
    "    my_dct = {}\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for i,batch in enumerate(val_data_loader):\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            preds = model(batch[0].to(device))\n",
    "\n",
    "            lns = batch[3]\n",
    "\n",
    "            decoded_tour, decoded_length = greedy_total(preds,batch[0],batch[2])\n",
    "\n",
    "            two_opt_tour, two_opt_length = two_opt(batch[2], decoded_tour)\n",
    "\n",
    "            value_gap = two_opt_length.detach() - lns.detach()\n",
    "\n",
    "            init_percentage_gap = torch.mean((value_gap/lns))*100\n",
    "\n",
    "            print(\"init gap: \", init_percentage_gap)\n",
    "\n",
    "            tol = 1000000\n",
    "\n",
    "            while tol > 0.00001:\n",
    "\n",
    "                two_opt_tour, two_opt_length = two_opt(batch[2], decoded_tour)\n",
    "\n",
    "                value_gap = two_opt_length-lns\n",
    "                new_percentage_gap = torch.mean((value_gap/lns))*100\n",
    "                print(\"new gap: \", new_percentage_gap)\n",
    "                tol = init_percentage_gap - new_percentage_gap\n",
    "\n",
    "                print(tol)\n",
    "\n",
    "                init_percentage_gap = new_percentage_gap\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    my_dct[\"mean_gap\"] = new_percentage_gap\n",
    "    my_dct[\"min_gap\"] = 100*(torch.min(torch.div(two_opt_length, lns))-1).item()\n",
    "    my_dct[\"max_gap\"] = 100*(torch.max(torch.div(two_opt_length, lns))-1).item()\n",
    "    my_dct[\"values\"] = 100*(torch.div(two_opt_length, lns)-1).numpy()\n",
    "    my_dct[\"solution_time\"] = end-start \n",
    "    \n",
    "    return my_dct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunBenchmarks(instance_type, instance_size):\n",
    "\n",
    "    model = Net(instance_size,ff_dim=ff_dim)\n",
    "\n",
    "    model.to(device)    \n",
    "    \n",
    "    data = np.loadtxt(\"BenchmarkInstances/{}_{}.csv\".format(instance_type, instance_size), delimiter=',')\n",
    "\n",
    "    val_dataset = CustomDataset(data, transform=ToTensor())\n",
    "    \n",
    "    val_data_loader = DataLoader(val_dataset, batch_size = len(val_dataset), shuffle=False, num_workers=1)\n",
    "\n",
    "    return GreedyDecoder(val_data_loader, model)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunBenchmarks(\"NS\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_names = [\"G1\", \"G2_2\", \"G3_1\", \"G3_2\", \"G3_3\", \"G4\", \"SG\", \"US\", \"UR\", \"NS\", \"NR\"]\n",
    "sizes = [20,50,100]\n",
    "parameter_list = []\n",
    "for item1 in instance_names:\n",
    "    for item2 in sizes:\n",
    "        parameter_list.append({\"instance_type\":item1, \"instance_size\":item2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunBenchmarks(instance_type, instance_size):\n",
    "\n",
    "    model = Net(instance_size,ff_dim=ff_dim)\n",
    "\n",
    "    model.to(device)    \n",
    "    \n",
    "    data = np.loadtxt(\"BenchmarkInstances/{}_{}.csv\".format(instance_type, instance_size), delimiter=',')\n",
    "\n",
    "    val_dataset = CustomDataset(data, transform=ToTensor())\n",
    "    \n",
    "    val_data_loader = DataLoader(val_dataset, batch_size = len(), shuffle=False, num_workers=mp.cpu_count())\n",
    "\n",
    "    return GreedyDecoder(val_data_loader, model)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,batch in enumerate(val_data_loader):\n",
    "    with torch.no_grad():\n",
    "        preds = model(batch[0].to(device))\n",
    "        labels = batch[1]\n",
    "        dist_mat = batch[2]\n",
    "        lns = batch[3]\n",
    "        decoded_tour, decoded_length = greedy_total(preds,batch[0],dist_mat)\n",
    "        two_opt_tour, two_opt_length = two_opt(dist_mat, decoded_tour)\n",
    "        two_opt_tour, two_opt_length = two_opt(dist_mat, two_opt_tour)\n",
    "        two_opt_tour, two_opt_length = two_opt(dist_mat, two_opt_tour)\n",
    "        #two_opt_tour, two_opt_length = two_opt(dist_mat, decoded_tour)\n",
    "        #two_opt_tour, two_opt_length = two_opt(dist_mat, decoded_tour)\n",
    "        #two_opt_tour, two_opt_length = two_opt(dist_mat, decoded_tour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_names = [\"G1\", \"G2_2\", \"G3_1\", \"G3_2\", \"G3_3\", \"G4\", \"SG\", \"US\", \"UR\", \"NS\", \"NR\"]\n",
    "res_list = []\n",
    "for item in instance_names:\n",
    "    res_list.append(GreedyDecoder_(20, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(\"eval.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 32.959229946136475,\n",
       " 'mean_gap': 5.629386329111288,\n",
       " 'max_gap': 16.724353458385053,\n",
       " 'min_gap': -1.2219485423514698e-07,\n",
       " 'perf': array([0.06413242, 0.05384084, 0.11348824, ..., 0.10274092, 0.01506078,\n",
       "        0.06232909])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[100,'G1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
